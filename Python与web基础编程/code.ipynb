{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import spectral\n",
    "from sklearn import model_selection\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_train = loadmat('/home/liuzixuan/实训/Python与web基础编程/9个类别的数据集-train/data2_train.mat')['data2_train']\n",
    "data3_train = loadmat('/home/liuzixuan/实训/Python与web基础编程/9个类别的数据集-train/data3_train.mat')['data3_train']\n",
    "data5_train = loadmat('/home/liuzixuan/实训/Python与web基础编程/9个类别的数据集-train/data5_train.mat')['data5_train']\n",
    "data6_train = loadmat('/home/liuzixuan/实训/Python与web基础编程/9个类别的数据集-train/data6_train.mat')['data6_train']\n",
    "data8_train = loadmat('/home/liuzixuan/实训/Python与web基础编程/9个类别的数据集-train/data8_train.mat')['data8_train']\n",
    "data10_train = loadmat('/home/liuzixuan/实训/Python与web基础编程/9个类别的数据集-train/data10_train.mat')['data10_train']\n",
    "data11_train = loadmat('/home/liuzixuan/实训/Python与web基础编程/9个类别的数据集-train/data11_train.mat')['data11_train']\n",
    "data12_train = loadmat('/home/liuzixuan/实训/Python与web基础编程/9个类别的数据集-train/data12_train.mat')['data12_train']\n",
    "data14_train = loadmat('/home/liuzixuan/实训/Python与web基础编程/9个类别的数据集-train/data14_train.mat')['data14_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#类别2\n",
    "label2_train = []\n",
    "for i in range(data2_train.shape[0]):\n",
    "    label2_train.append([2])\n",
    "#类别3\n",
    "label3_train = []\n",
    "for i in range(data3_train.shape[0]):\n",
    "    label3_train.append([3])\n",
    "#类别5\n",
    "label5_train = []\n",
    "for i in range(data5_train.shape[0]):\n",
    "    label5_train.append([5])\n",
    "#类别6\n",
    "label6_train = []\n",
    "for i in range(data6_train.shape[0]):\n",
    "    label6_train.append([6])\n",
    "#类别8\n",
    "label8_train = []\n",
    "for i in range(data8_train.shape[0]):\n",
    "    label8_train.append([8])\n",
    "#类别10\n",
    "label10_train = []\n",
    "for i in range(data10_train.shape[0]):\n",
    "    label10_train.append([10])\n",
    "#类别11\n",
    "label11_train = []\n",
    "for i in range(data11_train.shape[0]):\n",
    "    label11_train.append([11])\n",
    "#类别12\n",
    "label12_train = []\n",
    "for i in range(data12_train.shape[0]):\n",
    "    label12_train.append([12])\n",
    "#类别14\n",
    "label14_train = []\n",
    "for i in range(data14_train.shape[0]):\n",
    "    label14_train.append([14])\n",
    "\n",
    "#转换为数组\n",
    "label2_train = np.array(label2_train)\n",
    "label3_train = np.array(label3_train)\n",
    "label5_train = np.array(label5_train)\n",
    "label6_train = np.array(label6_train)\n",
    "label8_train = np.array(label8_train)\n",
    "label10_train = np.array(label10_train)\n",
    "label11_train = np.array(label11_train)\n",
    "label12_train = np.array(label12_train)\n",
    "label14_train = np.array(label14_train)\n",
    "#print(label2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#长度\n",
    "len0 = data2_train.shape[0]\n",
    "len1 = len0+data3_train.shape[0]\n",
    "len2 = len1+data5_train.shape[0]\n",
    "len3 = len2+data6_train.shape[0]\n",
    "len4 = len3+data8_train.shape[0]\n",
    "len5 = len4+data10_train.shape[0]\n",
    "len6 = len5+data11_train.shape[0]\n",
    "len7 = len6+data12_train.shape[0]\n",
    "len8 = len7+data14_train.shape[0]\n",
    "#print(len8)#6924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重组训练集(6924,201)\n",
    "train = np.zeros([len8,201])\n",
    "train[:len0,:200] = data2_train\n",
    "train[len0:len1,:200] = data3_train\n",
    "train[len1:len2,:200] = data5_train\n",
    "train[len2:len3,:200] = data6_train\n",
    "train[len3:len4,:200] = data8_train\n",
    "train[len4:len5,:200] = data10_train\n",
    "train[len5:len6,:200] = data11_train\n",
    "train[len6:len7,:200] = data12_train\n",
    "train[len7:,:200] = data14_train\n",
    "\n",
    "train[:len0,200:] = label2_train\n",
    "train[len0:len1,200:] = label3_train\n",
    "train[len1:len2,200:] = label5_train\n",
    "train[len2:len3,200:] = label6_train\n",
    "train[len3:len4,200:] = label8_train\n",
    "train[len4:len5,200:] = label10_train\n",
    "train[len5:len6,200:] = label11_train\n",
    "train[len6:len7,200:] = label12_train\n",
    "train[len7:,200:] = label14_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别字典为： {2.0: 1071, 3.0: 622, 5.0: 362, 6.0: 547, 8.0: 358, 10.0: 729, 11.0: 1841, 12.0: 445, 14.0: 949}\n"
     ]
    }
   ],
   "source": [
    "# 统计每类样本所含个数\n",
    "dict_k = {}\n",
    "for i in range(train.shape[0]):\n",
    "    for j in range(train.shape[1]):\n",
    "        if train[i][j] in [1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14]:\n",
    "            if train[i][j] not in dict_k:\n",
    "                dict_k[train[i][j]]=0\n",
    "            dict_k[train[i][j]] = dict_k[train[i][j]]+1\n",
    "            \n",
    "print('类别字典为：',dict_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分数据和标签及数据预处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "train_x = StandardScaler().fit_transform(train[:,:-1])\n",
    "#train_x = train[:,:200]\n",
    "train_y = train[:,200:]\n",
    "train_y = train_y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分训练集，测试集\n",
    "data_train,data_test,label_train,label_test = model_selection.train_test_split(train_x,train_y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 51, 0.8965351299326275)\n"
     ]
    }
   ],
   "source": [
    "#随机森林\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#导入网格搜索模块\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 存放不同参数取值，以及对应的精度，每一个元素都是一个三元组(a, b, c) \n",
    "results = [] \n",
    "# 最小叶子结点的参数取值 \n",
    "sample_leaf_options = list(range(1, 50, 3)) \n",
    "# 决策树个数参数取值 \n",
    "n_estimators_options = list(range(1, 100, 5))\n",
    "\n",
    "for leaf_size in sample_leaf_options: \n",
    "    for n_estimators_size in n_estimators_options: \n",
    "        alg = RandomForestClassifier(min_samples_leaf=leaf_size, n_estimators=n_estimators_size, random_state=50) \n",
    "        alg.fit(data_train, label_train) \n",
    "        predict = alg.predict(data_test) \n",
    "        # 用一个三元组，分别记录当前的 min_samples_leaf，n_estimators， 和在测试数据集上的精度 \n",
    "        results.append((leaf_size, n_estimators_size, (label_test == predict).mean())) \n",
    "        # 真实结果和预测结果进行比较，计算准确率 \n",
    "        #print((label_test == predict).mean()) \n",
    "\n",
    "# 打印精度最大的那一个三元组\n",
    "print(max(results, key=lambda x: x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用alg_best的正确率为： 0.8965351299326275\n"
     ]
    }
   ],
   "source": [
    "#随机森林\n",
    "alg_best = RandomForestClassifier(min_samples_leaf=1, n_estimators=51, random_state=50) \n",
    "alg_best.fit(data_train,label_train)\n",
    "pred_alg_best = alg_best.predict(data_test)\n",
    "accuracy_alg_best = alg_best.score(data_test,label_test)\n",
    "print('使用alg_best的正确率为：',accuracy_alg_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入测试集\n",
    "test = loadmat('/home/liuzixuan/实训/Python与web基础编程/data_test_final.mat')['data_test_final']#（2310,200）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuzixuan/test/lib/python3.5/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/liuzixuan/test/lib/python3.5/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#预处理测试集并进行预测\n",
    "test = StandardScaler().fit_transform(test)\n",
    "test = test.astype(int)\n",
    "predict_alg = alg_best.predict(test)\n",
    "dat = pd.DataFrame(predict_alg)\n",
    "dat.to_csv('/home/liuzixuan/实训/Python与web基础编程/test_alg_best3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
